{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCwbkVFxU5a9"
      },
      "source": [
        "# Envlogger and TFDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIQjTg467e41"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1DBTRzKDMmb"
      },
      "source": [
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca href=\"https://colab.research.google.com/github/google-research/rlds/blob/main/rlds/examples/tfds_rlu_atari.ipynb\" target=\"_parent\"\u003e\u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Run In Google Colab\"/\u003e\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV4QCcHs_7aW",
        "outputId": "215e35f3-98cd-4669-db39-56152b95febc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rlds in /usr/local/lib/python3.7/dist-packages (0.1.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from rlds) (2.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rlds) (1.19.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rlds) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py-\u003erlds) (1.15.0)\n",
            "Requirement already satisfied: astunparse\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (1.6.3)\n",
            "Requirement already satisfied: libclang\u003e=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (12.0.0)\n",
            "Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator\u003c2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (2.7.0)\n",
            "Requirement already satisfied: grpcio\u003c2.0,\u003e=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (1.43.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (2.7.0)\n",
            "Requirement already satisfied: h5py\u003e=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (3.1.0)\n",
            "Requirement already satisfied: protobuf\u003e=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (3.17.3)\n",
            "Requirement already satisfied: wheel\u003c1.0,\u003e=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (0.37.1)\n",
            "Requirement already satisfied: keras\u003c2.8,\u003e=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem\u003e=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (0.23.1)\n",
            "Requirement already satisfied: wrapt\u003e=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (1.13.3)\n",
            "Requirement already satisfied: gast\u003c0.5.0,\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (0.4.0)\n",
            "Requirement already satisfied: google-pasta\u003e=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions\u003e=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (3.10.0.2)\n",
            "Requirement already satisfied: keras-preprocessing\u003e=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers\u003c3.0,\u003e=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003erlds) (2.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py\u003e=2.9.0-\u003etensorflow-\u003erlds) (1.5.2)\n",
            "Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow-\u003erlds) (3.3.6)\n",
            "Requirement already satisfied: werkzeug\u003e=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow-\u003erlds) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow-\u003erlds) (1.8.1)\n",
            "Requirement already satisfied: requests\u003c3,\u003e=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow-\u003erlds) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow-\u003erlds) (0.6.1)\n",
            "Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow-\u003erlds) (1.35.0)\n",
            "Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow-\u003erlds) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow-\u003erlds) (0.4.6)\n",
            "Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard~=2.6-\u003etensorflow-\u003erlds) (4.8)\n",
            "Requirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard~=2.6-\u003etensorflow-\u003erlds) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard~=2.6-\u003etensorflow-\u003erlds) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard~=2.6-\u003etensorflow-\u003erlds) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata\u003e=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown\u003e=2.6.8-\u003etensorboard~=2.6-\u003etensorflow-\u003erlds) (4.10.0)\n",
            "Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=4.4-\u003emarkdown\u003e=2.6.8-\u003etensorboard~=2.6-\u003etensorflow-\u003erlds) (3.7.0)\n",
            "Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard~=2.6-\u003etensorflow-\u003erlds) (0.4.8)\n",
            "Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard~=2.6-\u003etensorflow-\u003erlds) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard~=2.6-\u003etensorflow-\u003erlds) (1.24.3)\n",
            "Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard~=2.6-\u003etensorflow-\u003erlds) (3.0.4)\n",
            "Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard~=2.6-\u003etensorflow-\u003erlds) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard~=2.6-\u003etensorflow-\u003erlds) (3.1.1)\n",
            "Requirement already satisfied: envlogger[tfds] in /usr/local/lib/python3.7/dist-packages (1.0.6)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.7/dist-packages (from envlogger[tfds]) (4.0.3)\n",
            "Requirement already satisfied: protobuf\u003e=3.14 in /usr/local/lib/python3.7/dist-packages (from envlogger[tfds]) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from envlogger[tfds]) (1.19.5)\n",
            "Requirement already satisfied: setuptools!=50.0.0 in /usr/local/lib/python3.7/dist-packages (from envlogger[tfds]) (57.4.0)\n",
            "Requirement already satisfied: dm-env in /usr/local/lib/python3.7/dist-packages (from envlogger[tfds]) (1.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from envlogger[tfds]) (0.12.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from envlogger[tfds]) (2.7.0)\n",
            "Requirement already satisfied: tfds-nightly in /usr/local/lib/python3.7/dist-packages (from envlogger[tfds]) (4.4.0.dev202201190107)\n",
            "Requirement already satisfied: six\u003e=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf\u003e=3.14-\u003eenvlogger[tfds]) (1.15.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from dm-env-\u003eenvlogger[tfds]) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem\u003e=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003eenvlogger[tfds]) (0.23.1)\n",
            "Requirement already satisfied: h5py\u003e=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003eenvlogger[tfds]) (3.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003eenvlogger[tfds]) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-estimator\u003c2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003eenvlogger[tfds]) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers\u003c3.0,\u003e=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003eenvlogger[tfds]) (2.0)\n",
            "Requirement already satisfied: keras-preprocessing\u003e=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003eenvlogger[tfds]) (1.1.2)\n",
            "Requirement already satisfied: google-pasta\u003e=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003eenvlogger[tfds]) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003eenvlogger[tfds]) (3.3.0)\n",
            "Requirement already satisfied: gast\u003c0.5.0,\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003eenvlogger[tfds]) (0.4.0)\n",
            "Requirement already satisfied: wrapt\u003e=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003eenvlogger[tfds]) (1.13.3)\n",
            "Requirement already satisfied: astunparse\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003eenvlogger[tfds]) (1.6.3)\n",
            "Requirement already satisfied: libclang\u003e=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003eenvlogger[tfds]) (12.0.0)\n",
            "Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003eenvlogger[tfds]) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions\u003e=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003eenvlogger[tfds]) (3.10.0.2)\n",
            "Requirement already satisfied: keras\u003c2.8,\u003e=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003eenvlogger[tfds]) (2.7.0)\n",
            "Requirement already satisfied: wheel\u003c1.0,\u003e=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003eenvlogger[tfds]) (0.37.1)\n",
            "Requirement already satisfied: grpcio\u003c2.0,\u003e=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003eenvlogger[tfds]) (1.43.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py\u003e=2.9.0-\u003etensorflow-\u003eenvlogger[tfds]) (1.5.2)\n",
            "Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (0.6.1)\n",
            "Requirement already satisfied: werkzeug\u003e=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (1.8.1)\n",
            "Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (1.35.0)\n",
            "Requirement already satisfied: requests\u003c3,\u003e=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (0.2.8)\n",
            "Requirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (4.2.4)\n",
            "Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata\u003e=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown\u003e=2.6.8-\u003etensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (4.10.0)\n",
            "Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=4.4-\u003emarkdown\u003e=2.6.8-\u003etensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (3.7.0)\n",
            "Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (0.4.8)\n",
            "Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (1.24.3)\n",
            "Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (2021.10.8)\n",
            "Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (3.0.4)\n",
            "Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard~=2.6-\u003etensorflow-\u003eenvlogger[tfds]) (3.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tfds-nightly-\u003eenvlogger[tfds]) (4.62.3)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tfds-nightly-\u003eenvlogger[tfds]) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tfds-nightly-\u003eenvlogger[tfds]) (5.4.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tfds-nightly-\u003eenvlogger[tfds]) (1.5.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tfds-nightly-\u003eenvlogger[tfds]) (0.3.4)\n",
            "Requirement already satisfied: googleapis-common-protos\u003c2,\u003e=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata-\u003etfds-nightly-\u003eenvlogger[tfds]) (1.54.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libgmpxx4ldbl\n",
            "Suggested packages:\n",
            "  gmp-doc libgmp10-doc libmpfr-dev\n",
            "The following NEW packages will be installed:\n",
            "  libgmp-dev libgmpxx4ldbl\n",
            "0 upgraded, 2 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 325 kB of archives.\n",
            "After this operation, 1,667 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgmpxx4ldbl amd64 2:6.1.2+dfsg-2 [8,964 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgmp-dev amd64 2:6.1.2+dfsg-2 [316 kB]\n",
            "Fetched 325 kB in 1s (302 kB/s)\n",
            "Selecting previously unselected package libgmpxx4ldbl:amd64.\n",
            "(Reading database ... 155229 files and directories currently installed.)\n",
            "Preparing to unpack .../libgmpxx4ldbl_2%3a6.1.2+dfsg-2_amd64.deb ...\n",
            "Unpacking libgmpxx4ldbl:amd64 (2:6.1.2+dfsg-2) ...\n",
            "Selecting previously unselected package libgmp-dev:amd64.\n",
            "Preparing to unpack .../libgmp-dev_2%3a6.1.2+dfsg-2_amd64.deb ...\n",
            "Unpacking libgmp-dev:amd64 (2:6.1.2+dfsg-2) ...\n",
            "Setting up libgmpxx4ldbl:amd64 (2:6.1.2+dfsg-2) ...\n",
            "Setting up libgmp-dev:amd64 (2:6.1.2+dfsg-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "#@title Install Pip packages\n",
        "!pip install rlds\n",
        "!pip install envlogger[tfds]\n",
        "!apt-get install libgmp-dev\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8fkB77rhV4d"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import os\n",
        "import rlds\n",
        "import tensorflow_datasets as tfds\n",
        "import envlogger\n",
        "from envlogger.backends import rlds_utils\n",
        "from envlogger.backends import tfds_backend_writer\n",
        "from envlogger.testing import catch_env\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import time\n",
        "from typing import Optional, List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8UBrhHiiKug"
      },
      "outputs": [],
      "source": [
        "#@title Auxiliary function to get dataset directories\n",
        "\n",
        "_METADATA_FILENAME='features.json'\n",
        "\n",
        "def get_ds_paths(pattern: str) -\u003e List[str]:\n",
        "  \"\"\"Returns the paths of tfds datasets under a (set of) directories.\n",
        "\n",
        "  We assume that a sub-directory with features.json file contains the dataset\n",
        "  files.\n",
        "\n",
        "  Args:\n",
        "    pattern: Root directory to search for dataset paths or a glob that matches\n",
        "      a set of directories, e.g. /some/path or /some/path/prefix*. See\n",
        "      tf.io.gfile.glob for the supported patterns.\n",
        "\n",
        "  Returns:\n",
        "    A list of paths that contain the environment logs.\n",
        "\n",
        "  Raises:\n",
        "    ValueError if the specified pattern matches a non-directory.\n",
        "  \"\"\"\n",
        "  paths = set([])\n",
        "  for root_dir in tf.io.gfile.glob(pattern):\n",
        "    if not tf.io.gfile.isdir(root_dir):\n",
        "      raise ValueError(f'{root_dir} is not a directory.')\n",
        "    print(f'root: {root_dir}')\n",
        "    for path, _, files in tf.io.gfile.walk(root_dir):\n",
        "      if _METADATA_FILENAME in files:\n",
        "        print(f'path: {path}')\n",
        "        paths.add(path)\n",
        "  return list(paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjilhMvUz5ex"
      },
      "source": [
        "# Generate a dataset\n",
        "\n",
        "In this example, we use the local TFDS backend. \n",
        "\n",
        "In order to generate the dataset, use the parameters below to configure:\n",
        "\n",
        "1. `root_dir`: where the dataset will be created.\n",
        "1. `num_episodes`: how many episodes to generate.\n",
        "1. `max_episodes_per_shard`: maximum number of episodes to include per file (episodes will be stored in multiple files and then read as a single dataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8FEjzUG0Alw"
      },
      "outputs": [],
      "source": [
        "generate_data_dir='/tmp/tensorflow_datasets/catch/' # @param\n",
        "num_episodes= 20 # @param\n",
        "max_episodes_per_shard = 1000 # @param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epUB8Ri6qKUg"
      },
      "outputs": [],
      "source": [
        "os.makedirs(generate_data_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvD3g8eQ8i_f",
        "outputId": "4c3b99b8-a067-4c51-9680-5265152140fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done wrapping environment with EnvironmentLogger.\n",
            "Training a random agent for 20 episodes...\n",
            "episode 0\n",
            "episode 1\n",
            "episode 2\n",
            "episode 3\n",
            "episode 4\n",
            "episode 5\n",
            "episode 6\n",
            "episode 7\n",
            "episode 8\n",
            "episode 9\n",
            "episode 10\n",
            "episode 11\n",
            "episode 12\n",
            "episode 13\n",
            "episode 14\n",
            "episode 15\n",
            "episode 16\n",
            "episode 17\n",
            "episode 18\n",
            "episode 19\n",
            "Done training a random agent for 20 episodes.\n"
          ]
        }
      ],
      "source": [
        "def record_data(data_dir, num_episodes, max_episodes_per_shard):\n",
        "  env = catch_env.Catch()\n",
        "\n",
        "  def step_fn(unused_timestep, unused_action, unused_env):\n",
        "    return {'timestamp_ns': time.time_ns()}\n",
        "\n",
        "  ds_config = tfds.rlds.rlds_base.DatasetConfig(\n",
        "        name='catch_example',\n",
        "        observation_info=tfds.features.Tensor(\n",
        "            shape=(10, 5),\n",
        "            dtype=tf.float32,\n",
        "            encoding=tfds.features.Encoding.ZLIB),\n",
        "        action_info=tf.int64,\n",
        "        reward_info=tf.float64,\n",
        "        discount_info=tf.float64,\n",
        "        step_metadata_info={'timestamp_ns': tf.int64})\n",
        "\n",
        "  with envlogger.EnvLogger(\n",
        "      env,\n",
        "      backend = tfds_backend_writer.TFDSBackendWriter(\n",
        "        data_directory=data_dir,\n",
        "        split_name='train',\n",
        "        max_episodes_per_file=max_episodes_per_shard,\n",
        "        ds_config=ds_config),\n",
        "      step_fn=step_fn) as env:\n",
        "    print('Done wrapping environment with EnvironmentLogger.')\n",
        "\n",
        "    print(f'Training a random agent for {num_episodes} episodes...')\n",
        "    for i in range(num_episodes):\n",
        "      print(f'episode {i}')\n",
        "      timestep = env.reset()\n",
        "      while not timestep.last():\n",
        "        action = np.random.randint(low=0, high=3)\n",
        "        timestep = env.step(action)\n",
        "    print(f'Done training a random agent for {num_episodes} episodes.')\n",
        "\n",
        "record_data(generate_data_dir, num_episodes, max_episodes_per_shard)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RkYWg1A_8jX"
      },
      "source": [
        "# Recover a dataset\n",
        "\n",
        "When the process of generating one dataset didn't finish properly, it is possible for the last shard to be incomplete. Envlogger provides the functionality to recover this last shard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyojLdQJAX_Z"
      },
      "outputs": [],
      "source": [
        "recover_dataset_path = '/tmp/tensorflow_datasets/catch/' # @param\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSdPMF8V_8LP"
      },
      "outputs": [],
      "source": [
        "builder = tfds.core.builder_from_directory(recover_dataset_path)\n",
        "builder = rlds_utils.maybe_recover_last_shard(builder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4JlcMxwBBmz"
      },
      "source": [
        "Recover one shard may take some time: if the last shard was not finalized correctly, it needs to read the full shard. Another option is to skip the data\n",
        "from the last shard and just call `rename_shards` to make sure all shards' files have the correct name (before exit, Envlogger renames all the shard files to comply with TFDS, if this didn't finish properly, the filenames would be incorrect)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbN8iSm1BfvO"
      },
      "outputs": [],
      "source": [
        "builder = tfds.core.builder_from_directory(recover_dataset_path)\n",
        "rlds_utils.rename_shards(recover_dataset_path, builder.info.splits, builder.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh63bHYz_mPO"
      },
      "source": [
        "# Load one dataset\n",
        "\n",
        "Loading one dataset generated with the TFDS backend uses just regular TFDS functionality.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y2S_CaME6be"
      },
      "outputs": [],
      "source": [
        "load_dataset_path = '/tmp/tensorflow_datasets/catch/' # @param\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYbA7kX_EgSH",
        "outputId": "c27c566b-c9ec-4755-ad98-98cbfb8210c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n"
          ]
        }
      ],
      "source": [
        "loaded_dataset = tfds.core.builder_from_directory(load_dataset_path).as_dataset(split='all')\n",
        "\n",
        "for e in loaded_dataset:\n",
        "  print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAp3HA5JFWYR"
      },
      "source": [
        "# Load a dataset from multiple directories\n",
        "\n",
        "Although TFDS doesn't support direct loading of one dataset from multiple directories, it is possible to do so with `tf.data` functions as long as the data has the same shape. Below we provide several examples of how to combine data from multiple runs of the environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajotTik0GJKr"
      },
      "outputs": [],
      "source": [
        "multiple_dataset_path = '/tmp/tensorflow_datasets/catch' # @param\n",
        "subdir_A = 'subdir_A' # @param\n",
        "subdir_B = 'subdir_B' # @param\n",
        "\n",
        "dir_A = os.path.join(multiple_dataset_path, subdir_A)\n",
        "dir_B = os.path.join(multiple_dataset_path, subdir_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiQ9xI3eCtzF",
        "outputId": "17ebb87c-f710-4972-93b6-687ce116b08e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done wrapping environment with EnvironmentLogger.\n",
            "Training a random agent for 20 episodes...\n",
            "episode 0\n",
            "episode 1\n",
            "episode 2\n",
            "episode 3\n",
            "episode 4\n",
            "episode 5\n",
            "episode 6\n",
            "episode 7\n",
            "episode 8\n",
            "episode 9\n",
            "episode 10\n",
            "episode 11\n",
            "episode 12\n",
            "episode 13\n",
            "episode 14\n",
            "episode 15\n",
            "episode 16\n",
            "episode 17\n",
            "episode 18\n",
            "episode 19\n",
            "Done training a random agent for 20 episodes.\n",
            "Done wrapping environment with EnvironmentLogger.\n",
            "Training a random agent for 20 episodes...\n",
            "episode 0\n",
            "episode 1\n",
            "episode 2\n",
            "episode 3\n",
            "episode 4\n",
            "episode 5\n",
            "episode 6\n",
            "episode 7\n",
            "episode 8\n",
            "episode 9\n",
            "episode 10\n",
            "episode 11\n",
            "episode 12\n",
            "episode 13\n",
            "episode 14\n",
            "episode 15\n",
            "episode 16\n",
            "episode 17\n",
            "episode 18\n",
            "episode 19\n",
            "Done training a random agent for 20 episodes.\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(dir_A, exist_ok=True)\n",
        "os.makedirs(dir_B, exist_ok=True)\n",
        "record_data(dir_A, num_episodes, max_episodes_per_shard)\n",
        "record_data(dir_B, num_episodes, max_episodes_per_shard)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWSS8HKlhZlU"
      },
      "source": [
        "## Option 1: Interleave. \n",
        "\n",
        "This should allow for better shuffling. The better paramenters for cycle and so on would have to be investigated (the underlying datasets are also using interleaving to shuffle the reads from the files underneath)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiQIocrSic0Y",
        "outputId": "2593a41b-a0a5-4a66-a6ed-5dc8738d75e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root: /tmp/tensorflow_datasets/catch\n",
            "path: /tmp/tensorflow_datasets/catch\n",
            "path: /tmp/tensorflow_datasets/catch/subdir_B\n",
            "path: /tmp/tensorflow_datasets/catch/subdir_A\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n"
          ]
        }
      ],
      "source": [
        "def load_tfds_dataset_interleave(pattern:str,\n",
        "                      cycle_length: int=tf.data.AUTOTUNE,\n",
        "                      block_length: Optional[int]=None,\n",
        "                      num_parallel_calls: int=tf.data.AUTOTUNE,\n",
        "                      deterministic: bool=False,\n",
        "                      ) -\u003e tf.data.Dataset:\n",
        "  paths = get_ds_paths(pattern)\n",
        "  builders = [tfds.core.builder_from_directory(p).as_dataset(split='all') for p in paths]\n",
        "  return tf.data.Dataset.from_tensor_slices(builders).interleave(\n",
        "      lambda ds: ds, \n",
        "      cycle_length=cycle_length, \n",
        "      block_length=block_length, \n",
        "      num_parallel_calls=num_parallel_calls, \n",
        "      deterministic=deterministic)\n",
        "\n",
        "\n",
        "ds = load_tfds_dataset_interleave(multiple_dataset_path)\n",
        "\n",
        "for e in ds.take(5):\n",
        "  print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vApjqo1CLIIT"
      },
      "source": [
        "## Option 2: Flat Map\n",
        "\n",
        "This is the simplest option to read the datasets sequentially."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQBO-clf-cfZ",
        "outputId": "1447f442-0a59-4f87-c956-bb93921a756d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root: /tmp/tensorflow_datasets/catch\n",
            "path: /tmp/tensorflow_datasets/catch\n",
            "path: /tmp/tensorflow_datasets/catch/subdir_B\n",
            "path: /tmp/tensorflow_datasets/catch/subdir_A\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n"
          ]
        }
      ],
      "source": [
        "def load_tfds_dataset_flat_map(pattern:str) -\u003e tf.data.Dataset:\n",
        "  paths = get_ds_paths(pattern)\n",
        "  builders = [tfds.core.builder_from_directory(p).as_dataset(split='all') for p in paths]\n",
        "\n",
        "  return tf.data.Dataset.from_tensor_slices(builders).flat_map(lambda ds: ds)\n",
        "\n",
        "\n",
        "ds = load_tfds_dataset_flat_map(multiple_dataset_path)\n",
        "\n",
        "for e in ds.take(5):\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxumFQATLTk0"
      },
      "source": [
        "## Option 3: Concatenate\n",
        "Another option to read the datasets sequentially. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brDmYLofCc-t",
        "outputId": "003b7040-f4b8-48d6-83b7-d9a23bea8899"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root: /tmp/tensorflow_datasets/catch\n",
            "path: /tmp/tensorflow_datasets/catch\n",
            "path: /tmp/tensorflow_datasets/catch/subdir_B\n",
            "path: /tmp/tensorflow_datasets/catch/subdir_A\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n",
            "{'steps': \u003c_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}\u003e}\n"
          ]
        }
      ],
      "source": [
        "def load_tfds_dataset_concat(pattern:str) -\u003e tf.data.Dataset:\n",
        "  paths = get_ds_paths(pattern)\n",
        "  builders = [tfds.core.builder_from_directory(p).as_dataset(split='all') for p in paths]\n",
        "  ds = builders[0]\n",
        "  for i in range(1, len(builders)):\n",
        "    ds = ds.concatenate(builders[i])\n",
        "  return ds\n",
        "\n",
        "ds = load_tfds_dataset_concat(multiple_dataset_path)\n",
        "\n",
        "for e in ds.take(5):\n",
        "  print(e)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TFDS_splits_loader.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
